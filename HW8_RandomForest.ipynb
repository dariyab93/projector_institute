{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d44e7-09b3-4ba7-8975-c9368f1d2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "# reuse the preprocessing approach from the previous homework\n",
    "# reuse validation approach from the previous homework. \n",
    "# it should be exactly the same because we want to compare the models\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f9e8079-0f18-4cbf-9de4-af6277d6c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5299cc6e-8ef4-42f9-8825-edb6eeb8fbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the titanic dataset \n",
    "train = pd.read_csv('/Users/dariyab/Desktop/projector/ML/Decision Trees /titanic/train.csv')\n",
    "train.shape\n",
    "train.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd7be3bf-52d0-48a9-bda0-eb45f054e779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare survival rates between men and women\n",
    "train[['Sex','Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e9066b86-6be9-4840-9407-5f1d91d3254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare survival rates between passanger classes \n",
    "train[['Pclass','Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "42999a03-9d3d-4318-aaec-7fd61099823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Data\n",
    "#Selecting features\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "X = train[features] #our features\n",
    "y = train['Survived'] # the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "abff2aee-4398-448f-b865-3179006b9cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare\n",
       "0         3    male  22.0      1      0   7.2500\n",
       "1         1  female  38.0      1      0  71.2833\n",
       "2         3  female  26.0      0      0   7.9250\n",
       "3         1  female  35.0      1      0  53.1000\n",
       "4         3    male  35.0      0      0   8.0500\n",
       "..      ...     ...   ...    ...    ...      ...\n",
       "886       2    male  27.0      0      0  13.0000\n",
       "887       1  female  19.0      0      0  30.0000\n",
       "888       3  female  28.0      1      2  23.4500\n",
       "889       1    male  26.0      0      0  30.0000\n",
       "890       3    male  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling missing values for some feature columns with the median of those columns. Robust to ouliers. \n",
    "X['Age'].fillna(X['Age'].median(), inplace = True) \n",
    "X['Fare'].fillna(X['Fare'].median(), inplace = True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8255829d-adbc-43a5-8c08-044ea7a0a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age  SibSp  Parch  Fare  Sex_male\n",
       "0         3   22      1      0     7         1\n",
       "1         1   38      1      0    71         0\n",
       "2         3   26      0      0     7         0\n",
       "3         1   35      1      0    53         0\n",
       "4         3   35      0      0     8         1\n",
       "..      ...  ...    ...    ...   ...       ...\n",
       "886       2   27      0      0    13         1\n",
       "887       1   19      0      0    30         0\n",
       "888       3   28      1      2    23         0\n",
       "889       1   26      0      0    30         1\n",
       "890       3   32      0      0     7         1\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding the categorical variable of \"Sex\" into 0s and 1s. #1 means the person was male\n",
    "\n",
    "X = pd.get_dummies(X, columns =['Sex'], drop_first = True).astype(int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1fa74e4-4ef0-4795-a1f5-9ad7302a6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the bagging model (from sklearn)\n",
    "# define the hyperparameters grid\n",
    "# define the grid search with cross validation using previously defined validation method\n",
    "# train the model\n",
    "# print the best hyperparameters\n",
    "# print the best score on train and validation data, estimate the generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a73bd14f-199a-4dc1-9bd2-092862e3eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'base_estimator__max_depth': None, 'base_estimator__min_samples_leaf': 3, 'max_features': 0.7, 'max_samples': 0.8}\n",
      "Best accuracy:  0.846218065407068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#Bagging model with the decision tree \n",
    "bagging_model = BaggingClassifier(base_estimator = dt, n_estimators = 25, random_state = 42 )\n",
    "\n",
    "#Stratified K-fold validation \n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42) \n",
    "\n",
    "#Hyperparameters for tuning the bagging model\n",
    "parameters = {\n",
    "    \"max_features\": [0.7, 0.8, 0.9], \n",
    "    \"max_samples\": [0.7, 0.8, 0.9], \n",
    "    \"base_estimator__max_depth\": [None, 4, 8, 12, 15],\n",
    "    \"base_estimator__min_samples_leaf\": [1, 2, 3, 5, 8]\n",
    "}\n",
    "\n",
    "#define grid search \n",
    "\n",
    "grid_search = GridSearchCV(estimator = bagging_model, \n",
    "                           param_grid = parameters, \n",
    "                           cv = skf, \n",
    "                           scoring = 'accuracy')\n",
    "\n",
    "#train the model                           \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#get the best parameters \n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_ \n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best accuracy: \", best_score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "974cd20a-d41d-4e5a-a7ff-d9c57cf70309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom Bagging Classifier\n",
    "class CustomBaggingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, n_estimators=25, max_samples=0.8, max_features=0.8):\n",
    "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier()\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        max_samples = int(self.max_samples * n_samples)\n",
    "        max_features = int(self.max_features * n_features)\n",
    "\n",
    "        # Train the estimator on drawn samples and features\n",
    "        for i in range(self.n_estimators):\n",
    "            # Draw samples with replacement\n",
    "            sample_indices = np.random.choice(n_samples, max_samples, replace=True)\n",
    "            X_sample = X.iloc[sample_indices]\n",
    "            y_sample = y.iloc[sample_indices]\n",
    "\n",
    "            # Draw features without replacement\n",
    "            feature_indices = np.random.choice(n_features, max_features, replace=False)\n",
    "            X_sample = X_sample.iloc[:, feature_indices]\n",
    "\n",
    "            # Clone the base estimator and fit it\n",
    "            estimator = clone(self.base_estimator)\n",
    "            estimator.fit(X_sample, y_sample)\n",
    "            self.estimators.append((estimator, feature_indices))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([estimator.predict(X.iloc[:, feature_indices]) for estimator, feature_indices in self.estimators])\n",
    "        return np.array([np.bincount(pred).argmax() for pred in predictions.T])  # Majority voting\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_sum = np.zeros((X.shape[0], len(np.unique([estimator[0].classes_ for estimator in self.estimators]))))\n",
    "        for estimator, feature_indices in self.estimators:\n",
    "            proba_sum += estimator.predict_proba(X.iloc[:, feature_indices])\n",
    "        return proba_sum / self.n_estimators\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"base_estimator\": self.base_estimator, \"n_estimators\": self.n_estimators,\n",
    "                \"max_samples\": self.max_samples, \"max_features\": self.max_features}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7f637b9b-2f7f-41be-89dc-387e893fcba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8651685393258427\n",
      "Best Hyperparameters: {'n_estimators': 25, 'max_depth': 5, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the base estimator\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25],  # Number of trees in the bagging classifier\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5]  # Minimum samples required to split an internal node\n",
    "}\n",
    "# Best score and hyperparameters for reference\n",
    "best_score = 0\n",
    "best_hyperparams = {}\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for min_samples_split in param_grid['min_samples_split']:\n",
    "                # Create a new instance of the base estimator with the current hyperparameters\n",
    "                base_estimator = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "                \n",
    "                # Create the custom bagging classifier with the current hyperparameters\n",
    "                custom_bagging_model = CustomBaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
    "\n",
    "                # Fit the model on the current training fold\n",
    "                custom_bagging_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "                # Make predictions on the validation fold\n",
    "                y_val_pred = custom_bagging_model.predict(X_val_fold)\n",
    "\n",
    "                # Calculate accuracy for the current fold\n",
    "                val_score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "               # print(f\"Fold {fold + 1} Accuracy with n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples_split}: {val_score}\")\n",
    "\n",
    "                # Update best score and hyperparameters if current score is better\n",
    "                if val_score > best_score:\n",
    "                    best_score = val_score\n",
    "                    best_hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split}\n",
    "\n",
    "print(\"Best Accuracy:\", best_score)\n",
    "print('Best Hyperparameters:', best_hyperparams)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a662683-0b13-4db0-98cd-97bbe4df5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy on Validation Data: 0.8707865168539326\n",
      "Best Hyperparameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "#using the scikitlearn random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Best score and hyperparameters for reference\n",
    "best_score = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25, 50],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Looping through each of the validation and train sets\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Loop through the hyperparameters\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for min_samples_split in param_grid['min_samples_split']:\n",
    "                # Create a new Random Forest model with current hyperparameters\n",
    "                rf_model.set_params(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "                # Fit the model on the current training fold\n",
    "                rf_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "                # Make predictions on the validation fold\n",
    "                y_val_pred = rf_model.predict(X_val_fold)\n",
    "\n",
    "                # Calculate accuracy for the current fold\n",
    "                val_score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "\n",
    "                # Update best score and hyperparameters if current score is better\n",
    "                if val_score > best_score:\n",
    "                    best_score = val_score\n",
    "                    best_hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split}\n",
    "\n",
    "# Final evaluation on the entire training data with the best hyperparameters\n",
    "rf_model.set_params(**best_hyperparams)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Accuracy on Validation Data:\", best_score)\n",
    "print(\"Best Hyperparameters:\", best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc376d76-b6d6-439f-a768-c7c12c8a75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest custom \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom Random Forest Classifier\n",
    "class CustomRandomForestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, n_estimators=25, max_samples=0.8, max_features=0.8):\n",
    "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier()\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        max_samples = int(self.max_samples * n_samples)\n",
    "        max_features = int(self.max_features * n_features)\n",
    "\n",
    "        # Train the estimator on drawn samples and features\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Draw samples with replacement\n",
    "            sample_indices = np.random.choice(n_samples, max_samples, replace=True)\n",
    "            X_sample = X.iloc[sample_indices]\n",
    "            y_sample = y.iloc[sample_indices]\n",
    "\n",
    "            # Draw features without replacement\n",
    "            feature_indices = np.random.choice(n_features, max_features, replace=False)\n",
    "            X_sample = X_sample.iloc[:, feature_indices]\n",
    "\n",
    "            # Clone the base estimator and fit it\n",
    "            estimator = clone(self.base_estimator)\n",
    "            estimator.fit(X_sample, y_sample)\n",
    "            self.estimators.append((estimator, feature_indices))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([estimator.predict(X.iloc[:, feature_indices]) for estimator, feature_indices in self.estimators])\n",
    "        return np.array([np.bincount(pred).argmax() for pred in predictions.T])  # Majority voting\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_sum = np.zeros((X.shape[0], len(np.unique([estimator[0].classes_ for estimator in self.estimators]))))\n",
    "        for estimator, feature_indices in self.estimators:\n",
    "            proba_sum += estimator.predict_proba(X.iloc[:, feature_indices])\n",
    "        return proba_sum / self.n_estimators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0df4c310-5be6-485b-83bd-f6f3861c404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy on Validation Data: 0.8547486033519553\n",
      "Best Hyperparameters: {'n_estimators': 25, 'max_depth': None, 'min_samples_split': 2}\n",
      "Estimated Generalization Error: 0.0786516853932584\n"
     ]
    }
   ],
   "source": [
    "#Custom random forest model on titanic dataset\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25],  # Number of trees in the random forest\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5]  # Minimum samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Best score and hyperparameters for reference\n",
    "best_score = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "# Looping through each of the validation and train sets\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Loop through the hyperparameters\n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            for min_samples_split in param_grid['min_samples_split']:\n",
    "                # Create a new instance of the base estimator with the current hyperparameters\n",
    "                base_estimator = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "                \n",
    "                custom_random_forest_model = CustomRandomForestClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
    "\n",
    "                # Fit the model \n",
    "                custom_random_forest_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "                # Make predictions\n",
    "                y_val_pred = custom_random_forest_model.predict(X_val_fold)\n",
    "\n",
    "                # Calculate accuracy \n",
    "                val_score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "                if val_score > best_score:\n",
    "                    best_score = val_score\n",
    "                    best_hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split}\n",
    "\n",
    "# Final evaluation on the entire training data with the best hyperparameters\n",
    "best_base_estimator = DecisionTreeClassifier(max_depth=best_hyperparams['max_depth'], min_samples_split=best_hyperparams['min_samples_split'])\n",
    "best_model = CustomRandomForestClassifier(base_estimator=best_base_estimator, n_estimators=best_hyperparams['n_estimators'])\n",
    "best_model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Best Accuracy on Validation Data:\", best_score)\n",
    "print(\"Best Hyperparameters:\", best_hyperparams)\n",
    "\n",
    "# Estimate generalization error\n",
    "generalization_error = 1 - final_val_score\n",
    "print(\"Estimated Generalization Error:\", generalization_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "03b1aa0c-0075-4da7-80fb-22ceee812a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset \n",
    "test = pd.read_csv('/Users/dariyab/Desktop/projector/ML/Decision Trees /titanic/test.csv')\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "X_test = test[features]\n",
    "X_test['Age'].fillna(X_test['Age'].median(), inplace = True) \n",
    "X_test['Fare'].fillna(X_test['Fare'].median(), inplace = True)\n",
    "X_test.head()\n",
    "X_test = pd.get_dummies(X_test, columns = ['Sex'], drop_first = True).astype(int)\n",
    "#reordering X_test columns so that they match X_train\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "438f292a-5805-4c48-8e6c-11f402cbfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's test our best model on the test dataset: \n",
    "# Make predictions on the test data\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission.to_csv('submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a8b5e-a231-496f-8437-e1c02a77b936",
   "metadata": {},
   "source": [
    "### After submitting to Kaggle, my score for the best model was unfortunately only 74% on the test dataset. I think it's because I had a hard time using gridsearch CV with my custom scripts and couldn't tune the hyperparameters properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da4ac1-813d-4b36-a0e1-798bad608335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
